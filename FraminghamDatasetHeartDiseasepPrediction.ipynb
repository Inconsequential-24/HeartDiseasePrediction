{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9zQ85j0u3fVHsaEblH7ZT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Inconsequential-24/HeartDiseasePrediction/blob/main/FraminghamDatasetHeartDiseasepPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOGISTIC REGRESSION:**"
      ],
      "metadata": {
        "id": "1lAJhhNRnTZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('framingham.csv')\n",
        "\n",
        "# Preprocess the data\n",
        "df = df.dropna()\n",
        "X = df.drop('TenYearCHD', axis=1) # Features\n",
        "y = df['TenYearCHD'] # Target variable\n",
        "X = pd.get_dummies(X, columns=['education', 'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp', 'diabetes']) # Convert categorical variables to binary\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Split the data into training and testing sets\n",
        "\n",
        "# Train the logistic regression model\n",
        "lr = LogisticRegression(random_state=42)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "# Calculate the F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UABmaU8nY6q",
        "outputId": "7622160c-3e8c-4b07-895e-55174323fa4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.046875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DECISION TREES:**"
      ],
      "metadata": {
        "id": "ACpb0akxnndR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('framingham.csv')\n",
        "\n",
        "# Drop rows with missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = df.drop('TenYearCHD', axis=1)\n",
        "y = df['TenYearCHD']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a decision tree classifier\n",
        "dtc = DecisionTreeClassifier()\n",
        "\n",
        "# Fit the model on the training data\n",
        "dtc.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = dtc.predict(X_test)\n",
        "\n",
        "# Calculate the F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"F1 Score: \", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XM7kKAXSnr5-",
        "outputId": "b92ef63b-650b-4d62-eadb-fd2d472ae706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score:  0.18326693227091637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RANDOM FORESTS:**"
      ],
      "metadata": {
        "id": "lr0jDlSVowod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('framingham.csv')\n",
        "\n",
        "# Drop rows with missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = df.drop('TenYearCHD', axis=1)\n",
        "y = df['TenYearCHD']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a random forest classifier\n",
        "rfc = RandomForestClassifier()\n",
        "\n",
        "# Fit the model on the training data\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = rfc.predict(X_test)\n",
        "\n",
        "# Calculate the F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"F1 Score: \", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAysbjKSo0W2",
        "outputId": "ccfc5cff-65d7-44e9-fbee-660cc0fb5d0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score:  0.09022556390977443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SUPPORT VECTOR MACHINE**"
      ],
      "metadata": {
        "id": "uY13xBs1nxgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('framingham.csv')\n",
        "\n",
        "# Drop rows with missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = df.drop('TenYearCHD', axis=1)\n",
        "y = df['TenYearCHD']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a SVM classifier\n",
        "svm = SVC()\n",
        "\n",
        "# Fit the model on the training data\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = svm.predict(X_test)\n",
        "\n",
        "# Calculate the F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"F1 Score: \", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4arq8uPBp_q2",
        "outputId": "9abf44e2-ebf3-4565-d8ae-887c28d86dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score:  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NEURAL NETWORKS:**"
      ],
      "metadata": {
        "id": "YRYPmfCZwPWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('framingham.csv')\n",
        "\n",
        "# Drop rows with missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = df.drop('TenYearCHD', axis=1)\n",
        "y = df['TenYearCHD']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Multi-Layer Perceptron classifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100, 100), activation='relu', solver='adam', random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "# Calculate the F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"F1 Score: \", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQhKCIh1wUCY",
        "outputId": "1dbba779-2258-4056-a11b-d37ec222514f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score:  0.047619047619047616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREDICTING THE PROBABLITY OF THE USER HAVING A HEART DISEASE USING THE DECISION TREE ALGORITHM (BEST F1 SCORE)**"
      ],
      "metadata": {
        "id": "BjMw5IfD1xox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('framingham.csv')\n",
        "\n",
        "# Replace missing values with the mean\n",
        "imp = SimpleImputer(strategy='mean')\n",
        "df = pd.DataFrame(imp.fit_transform(df), columns=df.columns)\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = df.drop(['TenYearCHD'], axis=1)\n",
        "y = df['TenYearCHD']\n",
        "\n",
        "# Initialize the decision tree classifier with default hyperparameters\n",
        "dtc = DecisionTreeClassifier()\n",
        "\n",
        "# Fit the model on the entire dataset\n",
        "dtc.fit(X, y)\n",
        "\n",
        "# Create a new dataframe with all the features used to train the model\n",
        "new_data = pd.DataFrame(columns=X.columns)\n",
        "new_data.loc[0] = X.mean()\n",
        "\n",
        "# Take user input for the features\n",
        "print('Please provide the following details:')\n",
        "age = float(input('Age: '))\n",
        "gender = float(input('Gender (0 for female, 1 for male): '))\n",
        "sysBP = float(input('Systolic Blood Pressure (mmHg): '))\n",
        "diaBP = float(input('Diastolic Blood Pressure (mmHg): '))\n",
        "BMI = float(input('Body Mass Index (kg/m^2): '))\n",
        "heartRate = float(input('Resting Heart Rate (bpm): '))\n",
        "glucose = float(input('Glucose (mg/dL): '))\n",
        "\n",
        "# Update the new dataframe with user input\n",
        "new_data.at[0, 'age'] = age\n",
        "new_data.at[0, 'male'] = gender\n",
        "new_data.at[0, 'sysBP'] = sysBP\n",
        "new_data.at[0, 'diaBP'] = diaBP\n",
        "new_data.at[0, 'BMI'] = BMI\n",
        "new_data.at[0, 'heartRate'] = heartRate\n",
        "new_data.at[0, 'glucose'] = glucose\n",
        "\n",
        "# Make predictions on the new data\n",
        "prediction = dtc.predict(new_data)\n",
        "probability = dtc.predict_proba(new_data)[:,1]\n",
        "\n",
        "# Print the results\n",
        "if prediction == 0:\n",
        "    print('You are not likely to have heart disease.')\n",
        "else:\n",
        "    print('You are likely to have heart disease.')\n",
        "print('Probability of having heart disease:', probability[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vghJUlED2ApE",
        "outputId": "69e48320-cd07-47f4-fe45-ae96ff7b9031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide the following details:\n",
            "Age: 21\n",
            "Gender (0 for female, 1 for male): 1\n",
            "Systolic Blood Pressure (mmHg): 128\n",
            "Diastolic Blood Pressure (mmHg): 80\n",
            "Body Mass Index (kg/m^2): 23\n",
            "Resting Heart Rate (bpm): 82\n",
            "Glucose (mg/dL): 179\n",
            "You are not likely to have heart disease.\n",
            "Probability of having heart disease: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DOWNLOAD THE DATASET & CODE:**\n",
        "*https://drive.google.com/drive/folders/1OPmnm4UatnPEk2p5KG8V4SaS44f-gEIx?usp=sharing*\n"
      ],
      "metadata": {
        "id": "X5yzlxzzPVJC"
      }
    }
  ]
}